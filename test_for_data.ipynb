{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import dgl\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.read_csv('data/graph_feature.csv')\n",
    "structure_df = pd.read_csv('data/graph_structure.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(session, df):  # df size = graph size\n",
    "    size = len(df)+1\n",
    "    G = nx.Graph()\n",
    "    nodes = range(1, size)\n",
    "    G.add_nodes_from(nodes)\n",
    "    edge_list = []\n",
    "    for uid in range(1, size):\n",
    "        neighbor_list = df[df['uid'] == uid].iloc[0]['linked'].split(',')\n",
    "        edge_list = [(int(uid), int(neighbor)) for neighbor in neighbor_list]\n",
    "        G.add_edges_from(edge_list)\n",
    "    return G\n",
    "\n",
    "def add_feature(graph, f_df):\n",
    "    feature_col_list = ['color', 'score', 'num_of_neighbor', 'hist_color', 'hist_neighbor', 'hist_skip']\n",
    "    for n in graph.nodes():\n",
    "        for f in feature_col_list:\n",
    "            graph.nodes[n][f] = f_df[f_df['uid']==n][f].tolist()[0]    # 取出uid符合的user的f欄位，從series型態轉成list再取值\n",
    "            \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n",
      "106\n"
     ]
    }
   ],
   "source": [
    "graph_list = []\n",
    "label_list = []\n",
    "for session in range(1, 14):\n",
    "    s_all_df = structure_df[structure_df['session'] == session]\n",
    "    for round in s_all_df['round'].unique():\n",
    "        \n",
    "        s_df = s_all_df[s_all_df['round'] == round]\n",
    "        f_df = feature_df.iloc[s_df.index]\n",
    "        \n",
    "        graph = create_graph(session, s_df)\n",
    "        graph = add_feature(graph, f_df)\n",
    "        graph_list.append(graph)\n",
    "\n",
    "        labels = f_df['action'].tolist()\n",
    "        label_list.append(labels)\n",
    "print(len(graph_list))\n",
    "print(len(label_list))\n",
    "\n",
    "# 感覺可以拆成80:20?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取得graph size的方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_list[0].number_of_nodes()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取得node feature vector的方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 0, 6, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for example\n",
    "list(graph_list[0].nodes[1].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vector_list = []\n",
    "for g in graph_list:\n",
    "    feature_vector_list.append([list(g.nodes[j].values()) for j in range(1, g.number_of_nodes()+1)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取得adj matirc的方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_12276\\2240364231.py:1: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  nx.adjacency_matrix(graph_list[0]).todense()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
       "        [1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       "        [1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1],\n",
       "        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1],\n",
       "        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0]], dtype=int32)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.adjacency_matrix(graph_list[0]).todense()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create dataset & dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class graphDataset(Dataset):\n",
    "    def __init__(self, graph_list, label_list):\n",
    "        feature_matrix_list = []\n",
    "        for g in graph_list:\n",
    "            feature_matrix = [list(g.nodes[j].values()) for j in range(1, g.number_of_nodes()+1)]\n",
    "            feature_matrix_list.append(torch.tensor(feature_matrix, dtype=torch.float))\n",
    "        \n",
    "        self.feature_matrix = feature_matrix_list\n",
    "        \n",
    "        adj_matrix_list = []\n",
    "        for g in graph_list:\n",
    "            adj_matrix = nx.adjacency_matrix(g).todense()\n",
    "            adj_matrix_list.append(torch.tensor(adj_matrix, dtype=torch.float))\n",
    "        self.adj_matrix = adj_matrix_list\n",
    "\n",
    "        labels = []\n",
    "        for i in range(len(label_list)):\n",
    "            labels.append(F.one_hot(torch.tensor(label_list[i], dtype=torch.int64)))\n",
    "        self.labels = labels\n",
    "        #print(len(self.feature_matrix), len(self.adj_matrix), len(self.labels))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = self.feature_matrix[idx]\n",
    "        adj_matrix = self.adj_matrix[idx]\n",
    "        labels = self.labels[idx]\n",
    "\n",
    "        return features, adj_matrix, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_12276\\3747036373.py:12: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  adj_matrix = nx.adjacency_matrix(g).todense()\n"
     ]
    }
   ],
   "source": [
    "training_data = graphDataset(graph_list, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loader = DataLoader(training_data, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, adj, labels = next(iter(training_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 6])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 16])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 3])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 6])\n",
      "tensor([[ 19., 493.,  35.,   4.,   0.,   2.],\n",
      "        [ 15., 426.,  35.,   6.,   0.,   0.],\n",
      "        [ 13., 383.,  30.,   4.,   0.,   1.],\n",
      "        [ 16., 476.,  35.,   4.,   1.,   1.],\n",
      "        [ 17., 477.,  35.,   4.,   1.,   1.],\n",
      "        [ 12., 450.,  37.,   6.,   0.,   0.],\n",
      "        [ 15., 467.,  37.,   5.,   1.,   0.],\n",
      "        [ 13., 449.,  37.,   5.,   1.,   0.],\n",
      "        [ 14., 433.,  37.,   5.,   1.,   0.],\n",
      "        [ 15., 433.,  42.,   6.,   1.,   0.],\n",
      "        [ 15., 417.,  37.,   5.,   0.,   1.],\n",
      "        [ 16., 416.,  37.,   5.,   0.,   1.],\n",
      "        [ 16., 449.,  37.,   5.,   0.,   1.],\n",
      "        [ 14., 349.,  36.,   6.,   0.,   0.],\n",
      "        [ 17., 433.,  36.,   4.,   0.,   2.],\n",
      "        [ 19., 443.,  35.,   4.,   0.,   2.]])\n"
     ]
    }
   ],
   "source": [
    "output = torch.mm(adj.squeeze(), features.squeeze())\n",
    "print(output.shape)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
