{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import dgl\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "跟 select action相同，只是label從action改成new_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.read_csv('data/change_color_df.csv')\n",
    "structure_df = pd.read_csv('data/graph_structure.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['color_red', 'color_black', 'color_green', 'color_blue', 'session', 'uid', 'round', 'score', 'num_of_neighbor', 'hist_color', 'hist_neighbor', 'hist_skip', 'new_color']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color_red</th>\n",
       "      <th>color_black</th>\n",
       "      <th>color_green</th>\n",
       "      <th>color_blue</th>\n",
       "      <th>session</th>\n",
       "      <th>uid</th>\n",
       "      <th>round</th>\n",
       "      <th>score</th>\n",
       "      <th>num_of_neighbor</th>\n",
       "      <th>hist_color</th>\n",
       "      <th>hist_neighbor</th>\n",
       "      <th>hist_skip</th>\n",
       "      <th>new_color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>996.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2153 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      color_red  color_black  color_green  color_blue  session   uid  round  \\\n",
       "0           0.0          0.0          0.0         1.0      1.0   1.0    1.0   \n",
       "1           0.0          0.0          0.0         1.0      1.0   2.0    1.0   \n",
       "2           0.0          0.0          0.0         1.0      1.0   3.0    1.0   \n",
       "3           0.0          0.0          0.0         1.0      1.0   4.0    1.0   \n",
       "4           0.0          0.0          0.0         1.0      1.0   5.0    1.0   \n",
       "...         ...          ...          ...         ...      ...   ...    ...   \n",
       "2148        0.0          1.0          0.0         0.0     13.0  16.0    6.0   \n",
       "2149        0.0          0.0          1.0         0.0     13.0  17.0    6.0   \n",
       "2150        1.0          0.0          0.0         0.0     13.0  18.0    6.0   \n",
       "2151        0.0          0.0          0.0         1.0     13.0  19.0    6.0   \n",
       "2152        0.0          0.0          0.0         1.0     13.0  20.0    6.0   \n",
       "\n",
       "      score  num_of_neighbor  hist_color  hist_neighbor  hist_skip  new_color  \n",
       "0       0.0              6.0         0.0            0.0        0.0        0.0  \n",
       "1       0.0              6.0         0.0            0.0        0.0        1.0  \n",
       "2       0.0              6.0         0.0            0.0        0.0        0.0  \n",
       "3       0.0              6.0         0.0            0.0        0.0        1.0  \n",
       "4       0.0              6.0         0.0            0.0        0.0        1.0  \n",
       "...     ...              ...         ...            ...        ...        ...  \n",
       "2148  100.0              7.0         0.2            0.0        0.8      996.0  \n",
       "2149  100.0              7.0         0.2            0.2        0.6      996.0  \n",
       "2150   89.0              9.0         0.4            0.0        0.6      996.0  \n",
       "2151  100.0              7.0         0.0            0.6        0.4      996.0  \n",
       "2152  100.0              6.0         0.0            0.4        0.6      996.0  \n",
       "\n",
       "[2153 rows x 13 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "col = feature_df.columns.tolist()\n",
    "col.remove('color')\n",
    "new_col = ['color_red', 'color_black', 'color_green', 'color_blue'] + col\n",
    "print(new_col)\n",
    "\n",
    "\n",
    "\n",
    "ct = ColumnTransformer([('color', OneHotEncoder(), [3])], remainder='passthrough')\n",
    "feature_onehot = np.array(ct.fit_transform(feature_df))\n",
    "feature_onehot_df = pd.DataFrame(feature_onehot, columns=new_col)\n",
    "feature_onehot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_onehot_df[feature_onehot_df['new_color'] != 996])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(session, df):  # df size = graph size\n",
    "    size = len(df)+1\n",
    "    G = nx.Graph()\n",
    "    nodes = range(1, size)\n",
    "    G.add_nodes_from(nodes)\n",
    "    edge_list = []\n",
    "    for uid in range(1, size):\n",
    "        neighbor_list = df[df['uid'] == uid].iloc[0]['linked'].split(',')\n",
    "        edge_list = [(int(uid), int(neighbor)) for neighbor in neighbor_list]\n",
    "        G.add_edges_from(edge_list)\n",
    "        G.add_edge(int(uid), int(uid))\n",
    "    return G\n",
    "\n",
    "def add_feature(graph, f_df):\n",
    "    feature_col_list = ['color_red', 'color_black', 'color_green', 'color_blue', 'score', 'num_of_neighbor', 'hist_color', 'hist_neighbor', 'hist_skip']\n",
    "    for n in graph.nodes():\n",
    "        for f in feature_col_list:\n",
    "            graph.nodes[n][f] = f_df[f_df['uid']==n][f].tolist()[0]    # 取出uid符合的user的f欄位，從series型態轉成list再取值\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_list = []\n",
    "label_list = []\n",
    "for session in range(1, 14):\n",
    "    s_all_df = structure_df[structure_df['session'] == session]\n",
    "    for round in s_all_df['round'].unique():\n",
    "        \n",
    "        s_df = s_all_df[s_all_df['round'] == round]\n",
    "        f_df = feature_onehot_df.iloc[s_df.index]\n",
    "        graph = create_graph(session, s_df)\n",
    "        graph = add_feature(graph, f_df)\n",
    "        graph_list.append(graph)\n",
    "\n",
    "        labels = f_df['new_color'].tolist()\n",
    "        label_list.append(labels)\n",
    "len(graph_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class graphDataset(Dataset):\n",
    "    def __init__(self, graph_list, label_list):\n",
    "        feature_matrix_list = []\n",
    "        for g in graph_list:\n",
    "            feature_matrix = [list(g.nodes[j].values()) for j in range(1, g.number_of_nodes()+1)]\n",
    "            feature_matrix_list.append(torch.tensor(feature_matrix, dtype=torch.float))\n",
    "        \n",
    "        self.feature_matrix = feature_matrix_list\n",
    "        \n",
    "        adj_matrix_list = []\n",
    "        for g in graph_list:\n",
    "            adj_matrix = nx.adjacency_matrix(g).todense()\n",
    "            adj_matrix_list.append(torch.tensor(adj_matrix, dtype=torch.float))\n",
    "        self.adj_matrix = adj_matrix_list\n",
    "\n",
    "        labels = []\n",
    "        for i in range(len(label_list)):\n",
    "            labels.append(torch.tensor(label_list[i], dtype=torch.int64))\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = self.feature_matrix[idx]\n",
    "        adj_matrix = self.adj_matrix[idx]\n",
    "        labels = self.labels[idx]\n",
    "\n",
    "        return features, adj_matrix, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvolutionalLayer(nn.modules.Module):\n",
    "    def __init__(self, in_feature, out_feature, bias=True):\n",
    "        super(GraphConvolutionalLayer, self).__init__()\n",
    "        self.in_feature = in_feature\n",
    "        self.out_feature = out_feature\n",
    "        self.weight = Parameter(torch.FloatTensor(in_feature, out_feature))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.FloatTensor(out_feature))\n",
    "        else:\n",
    "            self.bias = None\n",
    "    def forward(self, adj_matrix, features):\n",
    "        output = torch.mm(adj_matrix, features)\n",
    "        output = torch.mm(output, self.weight)\n",
    "        if(self.bias is not None):\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "    \n",
    "\n",
    "class GCN_Model(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim, dropout):\n",
    "        super(GCN_Model, self).__init__()\n",
    "        self.gcn = GraphConvolutionalLayer(in_dim, hidden_dim)\n",
    "        self.linear1 = torch.nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.linear2 = torch.nn.Linear(hidden_dim, out_dim)\n",
    "        self.dropout = dropout\n",
    "        \n",
    "    def forward(self, feature, adj_matrix):\n",
    "        x = torch.nn.functional.relu(self.gcn(adj_matrix, feature))\n",
    "        x = torch.nn.functional.dropout(x, self.dropout, training=self.training)\n",
    "        x = torch.nn.functional.relu(self.linear1(x))\n",
    "        x = torch.nn.functional.dropout(x, self.dropout, training=self.training)\n",
    "        x = self.linear2(x)\n",
    "        output = torch.nn.functional.softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, labels):\n",
    "    preds = output.max(1)[1].type_as(labels)\n",
    "    correct = preds.eq(labels).double().sum()\n",
    "    return np.round(correct / len(labels), 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在train step只針對new_color != 996的那些node做loss function計算 -> 利用index取出來?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, test_dataloader, optimizer, loss_fn, epoch, eval=True):\n",
    "    t = time.time()\n",
    "    loss_hist = []\n",
    "    for _ in range(epoch):\n",
    "        model.train()\n",
    "        for features, adj_matrix, labels in iter(train_dataloader):\n",
    "            features = features.squeeze()\n",
    "            adj_matrix = adj_matrix.squeeze()\n",
    "            labels = labels.squeeze()\n",
    "            \n",
    "            output = model(features, adj_matrix)\n",
    "            # 挑出label == 996的，不參與loss計算\n",
    "            excluded_index = []\n",
    "            for i in range(len(labels)):\n",
    "                if(labels[i] != 996):\n",
    "                    excluded_index.append(i)\n",
    "            if(excluded_index):\n",
    "                real_labels = torch.index_select(labels, dim=0, index=torch.tensor(excluded_index))\n",
    "                real_output = torch.index_select(output, dim=0, index=torch.tensor(excluded_index))\n",
    "                \n",
    "                loss = loss_fn(real_output, real_labels)\n",
    "                loss_hist.append(float(loss))\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        if(eval):\n",
    "            model.eval()\n",
    "            total_loss = 0\n",
    "            for features, adj_matrix, labels in iter(test_dataloader):\n",
    "                features = features.squeeze()\n",
    "                adj_matrix = adj_matrix.squeeze()\n",
    "                labels = labels.squeeze()\n",
    "                output = model(features, adj_matrix)\n",
    "                # 挑出label == 996的，不參與loss計算\n",
    "                excluded_index = []\n",
    "                for i in range(len(labels)):\n",
    "                    if(labels[i] != 996):\n",
    "                        excluded_index.append(i)\n",
    "                if(excluded_index):\n",
    "                    real_labels = torch.index_select(labels, dim=0, index=torch.tensor(excluded_index))\n",
    "                    # print(len(real_labels))\n",
    "                    real_output = torch.index_select(output, dim=0, index=torch.tensor(excluded_index))\n",
    "                    total_loss += float(loss_fn(real_output, real_labels))\n",
    "            print('eval avg loss: ', total_loss/len(test_dataloader))\n",
    "            print('acc: ', float(accuracy(real_output, real_labels)))\n",
    "            print('='*80)\n",
    "    return loss_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9880\\2866558056.py:12: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  adj_matrix = nx.adjacency_matrix(g).todense()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9880\\2866558056.py:18: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  labels.append(torch.tensor(label_list[i], dtype=torch.int64))\n"
     ]
    }
   ],
   "source": [
    "train_dataset = graphDataset(graph_list[:90], label_list[:90])\n",
    "test_dataset = graphDataset(graph_list[90:], label_list[90:])\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=1, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval avg loss:  1.214207462966442\n",
      "acc:  0.0\n",
      "================================================================================\n",
      "eval avg loss:  1.2056887075304985\n",
      "acc:  0.67\n",
      "================================================================================\n",
      "eval avg loss:  1.2028753608465195\n",
      "acc:  0.67\n",
      "================================================================================\n",
      "eval avg loss:  1.2003792375326157\n",
      "acc:  0.67\n",
      "================================================================================\n",
      "eval avg loss:  1.1986666396260262\n",
      "acc:  0.67\n",
      "================================================================================\n",
      "eval avg loss:  1.19773830473423\n",
      "acc:  0.67\n",
      "================================================================================\n",
      "eval avg loss:  1.1970538794994354\n",
      "acc:  0.67\n",
      "================================================================================\n",
      "eval avg loss:  1.1946364119648933\n",
      "acc:  0.67\n",
      "================================================================================\n",
      "eval avg loss:  1.1930092126131058\n",
      "acc:  0.67\n",
      "================================================================================\n",
      "eval avg loss:  1.19083421677351\n",
      "acc:  0.67\n",
      "================================================================================\n",
      "eval avg loss:  1.1913160160183907\n",
      "acc:  0.67\n",
      "================================================================================\n",
      "eval avg loss:  1.1915349513292313\n",
      "acc:  0.67\n",
      "================================================================================\n",
      "eval avg loss:  1.1917064934968948\n",
      "acc:  0.67\n",
      "================================================================================\n",
      "eval avg loss:  1.1914323344826698\n",
      "acc:  0.67\n",
      "================================================================================\n",
      "eval avg loss:  1.190403014421463\n",
      "acc:  0.67\n",
      "================================================================================\n",
      "eval avg loss:  1.1903092041611671\n",
      "acc:  0.67\n",
      "================================================================================\n",
      "eval avg loss:  1.1902308240532875\n",
      "acc:  0.67\n",
      "================================================================================\n",
      "eval avg loss:  1.190516658127308\n",
      "acc:  0.67\n",
      "================================================================================\n",
      "eval avg loss:  1.1916406899690628\n",
      "acc:  0.67\n",
      "================================================================================\n",
      "eval avg loss:  1.1925292164087296\n",
      "acc:  0.67\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "model = GCN_Model(9, 9, 4, 0.2)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "l = train(model, train_dataloader, test_dataloader, optimizer, loss_fn, epoch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('color_change.txt', 'w')\n",
    "for i in l:\n",
    "    f.write(str(i))\n",
    "    f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1680"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dasktop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af145336a072850b3afe5d93846e46bc6fbbea5f0cef0291180fc41145709614"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
